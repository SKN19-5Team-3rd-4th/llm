from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from typing import TypedDict, Annotated, Optional, Literal, List

from functools import partial
import operator
from dotenv import load_dotenv
import warnings
import json
import streamlit as st
import requests
from PIL import Image
import io

from modules.collect import ModelCollect
from modules.recommend import ModelRecommend, tool_rag_recommend
from modules.qna import ModelQna, tool_rag_qna

load_dotenv()

warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=RuntimeWarning)

# ì •ë³´ ì €ì¥ state ì„ ì–¸ --------------------

class GraphState(TypedDict):
    messages: Annotated[list, add_messages]                         # ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸

    current_stage: Literal["collect", "recommend", "qna", "exit"]   # í˜„ì¬ ì–´ë–¤ ì‘ì—…ì„ í•˜ê³  ìˆëŠ”ì§€ ì €ì¥

    collected_data: Optional[dict]                                  # ì‚¬ìš©ìì—ê²Œì„œ ëª¨ì€ ë°ì´í„°(ì •ë³´)ë¥¼ ì €ì¥í•˜ëŠ” ë”•ì…”ë„ˆë¦¬

    recommend_result: Annotated[Optional[List[str]], operator.add]  # ì‚¬ìš©ìì—ê²Œ ì¶”ì²œí•œ ê²°ê³¼(í•´ë‹¹ ì¶”ì²œ ê²°ê³¼ëŠ” ì¬ì¶”ì²œí• ë•Œì— ê³ ë ¤í•˜ì§€ ì•Šê²Œ í•˜ê¸° ìœ„í•¨)

    # None: ì•„ë¬´ í–‰ë™ë„ í•˜ì§€ ì•ŠìŒ, Skip: ë‹¤ìŒ ë‹¨ê³„ë¡œ, Continue: ì¶”ì²œ ë§Œì¡±, Retry: ì¶”ì²œ ë‹¤ì‹œ ë°›ê¸°, Restart: ì²˜ìŒë¶€í„° ì¬ì‹œì‘, QnA: QnAë¡œ ì´ë™
    user_action: Literal["None", "Skip", "Continue", "Retry", "Restart", "QnA", "Exit"]


initial_state = {
    "messages": [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”. AIì…ë‹ˆë‹¤.")],
    "current_stage": "collect",
    "user_action": "None",
    "collected_data": {
                "purpose": None,            
                "preferred_style": None,    
                "preferred_color": None,
                "plant_type": None,
                "season": None,
                "humidity": None,
                "has_dog": None,
                "has_cat": None,
                "isAirCond": None,
                "watering_frequency": None,
                "user_experience": None,
                "emotion": None
            },
    "recommend_result": " "
}
### tools ì„ ì–¸ ---------------------------
# tool í•¨ìˆ˜ ì„ ì–¸

# tools ì—ëŠ”, ê°ê° RAGë¥¼ ìˆ˜í–‰í•˜ëŠ” ë‘ê°€ì§€ í•¨ìˆ˜ê°€ ë“¤ì–´ê°€ì•¼ í•¨
tools = [tool_rag_recommend, tool_rag_qna]

### ë…¸ë“œ ì„ ì–¸ -----------------------------

def node_collect(state: GraphState, collector: ModelCollect):
    collected_data = collector.get_response(state["collected_data"])  # ì–´ë–¤ ì •ë³´ë¥¼ ì „ë‹¬í–ˆëŠ”ì§€ ì•Œì•„ì•¼ í•˜ë‹ˆê¹Œ collected_dataë„ ê°™ì´ ì „ë‹¬
    
    return {
        "current_stage" : "recommend",
        "collected_data": collected_data,
    }

def node_recommend(state: GraphState, recommender: ModelRecommend):

    response, recommend_result = recommender.get_response(state["messages"], state["collected_data"], state["recommend_result"])  

    return {
        "current_stage" : "recommend",
        "messages": [response],
        "recommend_result": recommend_result,
    }

def node_qna(state: GraphState, chatbot: ModelQna):
    response = chatbot.get_response(state["messages"])

    return {
        "current_stage": "qna",
        "messages": [response],
    }

def node_end_state(state:GraphState):
    return {
        "current_stage": "exit"
    }


### router ì„ ì–¸ -----------------------

# í•´ë‹¹ routerì˜ ê²°ê³¼ì— ë”°ë¼, ì–´ë–¤ ë…¸ë“œë¡œ í–¥í• ì§€ ì»¨íŠ¸ë¡¤
def main_router(state: GraphState):
    stage = state["current_stage"]
    action = state["user_action"]

    if action == "Restart":
        return "restart"
    
    if action == "Exit":
        return "exit"
    
    if action == "QnA":
        return "qna"
    
    
    if stage == "collect":
        if action == "Continue":
            return "recommend"
        
        if ModelCollect.is_data_enough(state["collected_data"]):
            return "recommend"
        else:
            return "collect"
    
    elif stage == "recommend":
        if action == "Continue":
            return "exit"
        
        elif action == "QnA":
            return "qna"
        else:   # action == "Retry"
            return "recommend"
    
    elif stage == "qna":
        return "qna"
    
    elif stage == "exit":
        return "exit"
    
def is_tool_calls(state: GraphState):
    last_message = state["messages"][-1]

    if last_message.tool_calls:
        return "tool_call"
    else:
        return "done"
    
def tool_back_to_caller(state: GraphState) -> str:
    current_state = state.get("current_stage")

    if current_state == "recommend":
        print(f"[ToolMessages] [RAG] [Pinecone Index name is plant-rec]")
    elif current_state == "qna":
        print(f"[ToolMessages] [RAG] [Pinecone Index name is plant-qna]")
    print(state["messages"][-1])

    if current_state and current_state in ["collect", "recommend", "qna"]:
        return current_state
    
    return "exit"


model_collect = ModelCollect(tools)
model_recommend = ModelRecommend(tools)
model_qna = ModelQna(tools)

workflow = StateGraph(GraphState)

workflow.add_node("collect", partial(node_collect, collector=model_collect))
workflow.add_node("recommend", partial(node_recommend, recommender=model_recommend))
workflow.add_node("qna", partial(node_qna, chatbot=model_qna))
workflow.add_node("exit", node_end_state)
workflow.add_node("rag_tool", ToolNode(tools))

workflow.add_edge("exit", END)
workflow.add_edge("collect", END)

workflow.add_conditional_edges(
    START,
    main_router,
    {
        "collect": "collect",
        "recommend": "recommend",
        "qna": "qna",
        "exit": "exit"
    }
)

workflow.add_conditional_edges(
    "recommend",
    is_tool_calls,
    {
        "tool_call": "rag_tool",
        "done": END,
    }
)

workflow.add_conditional_edges(
    "qna",
    is_tool_calls,
    {
        "tool_call": "rag_tool",
        "done": END,
    }
)

workflow.add_conditional_edges(
    "rag_tool",
    tool_back_to_caller,
    {
        "collect": "collect",
        "recommend": "recommend",
        "qna": "qna",
        "exit": "exit",
    }
)

### streamlit -----------------------

# ë©”ì‹œì§€ íŒŒì‹± í•¨ìˆ˜
def parse_ai_content(content):
    if isinstance(content, str) and content.startswith('{'):    # ë©”ì‹œì§€ê°€ json í˜•íƒœë¼ë©´ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        try:
            data = json.loads(content)
            if "assistant_message" in data: return data["assistant_message"], None
            if "response" in data: return data["response"], data["flowNm"]
        except: pass
    return content, None

if "is_collected" not in st.session_state:
    st.session_state.is_collected = False

if "collected_data" not in st.session_state:
    st.session_state.collected_data = {
                "purpose": None,            
                "preferred_style": None,    
                "preferred_color": None,
                "plant_type": None,
                "season": None,
                "humidity": None,
                "has_dog": None,
                "has_cat": None,
                "isAirCond": None,
                "watering_frequency": None,
                "user_experience": None,
                "emotion": None
            }

if st.session_state.is_collected is False:
    options = {
        "purpose": ["ê³µê¸° ì •í™”", "ì¸í…Œë¦¬ì–´", "ì„ ë¬¼", "í•™ìŠµ/ê´€ì°°", "ë°˜ë ¤ìš©"],
        "style": ["ëª¨ë˜/ì‹¬í”Œ", "ë¹ˆí‹°ì§€", "ë‚´ì¶”ëŸ´/ìš°ë“œ", "í™”ë ¤í•¨"],
        "color": ["ì´ˆë¡ìƒ‰(ê¸°ë³¸)", "ì•Œë¡ë‹¬ë¡", "í°ìƒ‰ ê½ƒ", "ë¶„í™/ë¹¨ê°• ê³„ì—´"],
        "type": ["ê´€ì—½ì‹ë¬¼", "ë‹¤ìœ¡/ì„ ì¸ì¥", "ê½ƒì´ í”¼ëŠ” ì‹ë¬¼", "í–‰ì‰ í”ŒëœíŠ¸"],
        "season": ["ë´„", "ì—¬ë¦„", "ê°€ì„", "ê²¨ìš¸", "ì‚¬ê³„ì ˆ ë¬´ê´€"],
        "humidity": ["ê±´ì¡°í•œ í¸", "ë³´í†µ", "ìŠµí•œ í¸"],
        "experience": ["ì‹ì§‘ì‚¬ ì…ë¬¸ (ì´ˆë³´)", "ê²½í—˜ ìˆìŒ (ì¤‘ìˆ˜)", "ì „ë¬¸ê°€ (ê³ ìˆ˜)"],
        "emotion": ["í–‰ë³µ/ê¸°ì¨", "ì°¨ë¶„í•¨/íë§", "ìš°ìš¸/ìœ„ë¡œ", "í”¼ê³¤/í™œë ¥í•„ìš”"],
    }

    with st.form(key="plant_preference_form"):
        collected_data = {
                "purpose": None,            
                "preferred_style": None,    
                "preferred_color": None,
                "plant_type": None,
                "season": None,
                "humidity": None,
                "has_dog": None,
                "has_cat": None,
                "isAirCond": None,
                "watering_frequency": None,
                "user_experience": None,
                "emotion": None
        }
        st.caption("ì¼ë¶€ í•­ëª©ì„ ì„ íƒí•œ í›„ í•˜ë‹¨ì˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

        col1, col2 = st.columns(2)

        def get_selection(label, options_list):
            selection = st.selectbox(label, ["ì„ íƒí•˜ì„¸ìš”"] + options_list)
            return selection if selection != "ì„ íƒí•˜ì„¸ìš”" else None

        def get_bool_selection(label):
            selection = st.selectbox(label, ["ì„ íƒí•˜ì„¸ìš”"] + options["yes_no"])
            if selection == "ì˜ˆ": return True
            elif selection == "ì•„ë‹ˆì˜¤": return False
            else: return None

        with col1:
            st.subheader("í™˜ê²½ ë° ëª©ì ")
            collected_data["purpose"] = get_selection("êµ¬ë§¤ ëª©ì ", options["purpose"])
            collected_data["season"] = get_selection("í˜„ì¬ ê³„ì ˆ", options["season"])
            collected_data["humidity"] = get_selection("ì„¤ì¹˜ ê³µê°„ ìŠµë„", options["humidity"])
            collected_data["user_experience"] = get_selection("ì‹ë¬¼ í‚¤ìš°ê¸° ê²½í—˜", options["experience"])

        with col2:
            st.subheader("ì·¨í–¥ ë° ê²½í—˜")
            collected_data["preferred_style"] = get_selection("ì„ í˜¸í•˜ëŠ” ìŠ¤íƒ€ì¼", options["style"])
            collected_data["preferred_color"] = get_selection("ì„ í˜¸í•˜ëŠ” ìƒ‰ìƒ", options["color"])
            collected_data["plant_type"] = get_selection("ì›í•˜ëŠ” ì‹ë¬¼ ì¢…ë¥˜", options["type"])
            collected_data["emotion"] = get_selection("í˜„ì¬ ê¸°ë¶„/ì–»ê³  ì‹¶ì€ ê°ì •", options["emotion"])

        st.divider()

        submitted = st.form_submit_button("ì‹ë¬¼ ì¶”ì²œ ë°›ê¸°")
    if submitted:
        st.session_state.collected_data = collected_data
        st.session_state.is_collected = True
else:
    initial_state = {
        "messages": [AIMessage(content="ì•ˆë…•í•˜ì„¸ìš”. AIì…ë‹ˆë‹¤.")],
        "current_stage": "recommend",
        "user_action": "None",
        "collected_data": st.session_state.collected_data,
        "recommend_result": " "
    }

    # "compile()" ì€ rerunë§ˆë‹¤ ì¬ì‚¬ìš©ë˜ë„ë¡ session_stateì— ì €ì¥
    if "app" not in st.session_state:
        memory = MemorySaver()
        st.session_state.app = workflow.compile(checkpointer=memory)

    st.set_page_config(page_title="PLANT AI", page_icon="ğŸŒ¿")

    st.title("A.P.T(AI Plant Teller)")


    app = st.session_state.app

    if "thread_id" not in st.session_state:
        st.session_state.thread_id = "user_1234" # ê³ ìœ  ID

    config = {"configurable": {"thread_id": st.session_state.thread_id}}

    # ì´ˆê¸° ë©”ì‹œì§€/ìƒíƒœê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
    current_state_snapshot = app.get_state(config)
    if not current_state_snapshot.values:
        app.invoke(initial_state, config=config)
        
        st.rerun()

    # í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°
    state_values = app.get_state(config).values
    messages = state_values.get("messages", [])
    current_stage = state_values.get("current_stage", "collect")
    collected_data = state_values.get("collected_data", {})


    with st.sidebar:
        st.header("ì§„í–‰ ìƒí™©")
        stage_map = {"collect": "ì •ë³´ ìˆ˜ì§‘", "recommend": "ì¶”ì²œ", "qna": "ìƒë‹´", "exit": "ì¢…ë£Œ"}
        st.info(f"í˜„ì¬ ë‹¨ê³„: **{stage_map.get(current_stage, current_stage)}**")

        if st.button("ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘"):
            # ìƒíƒœ ë¦¬ì…‹ ë¡œì§ (ìƒˆ thread_id ë°œê¸‰ ë“±)
            st.session_state.thread_id = f"user_{int(st.session_state.thread_id.split('_')[1]) + 1}"
            st.rerun()


    # íˆìŠ¤í† ë¦¬ ì¶œë ¥
    for msg in messages[1:]:
        if isinstance(msg, HumanMessage):
            with st.chat_message("user"):
                st.write(msg.content)
        elif isinstance(msg, AIMessage):
            if msg.content:
                text, flowNm = parse_ai_content(msg.content)
                with st.chat_message("assistant", avatar="ğŸŒ¿"):
                    if flowNm is not None:
                        with open("datas/flower_preprocessed_data.json", "r", encoding="utf-8") as f:
                            flower_list = json.load(f)

                        target = next((item for item in flower_list if item.get("flowNm") == flowNm), None)

                        if target is None:
                            st.warning(f"'{flowNm}' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            image_url = target.get("imgUrl1")

                            if not image_url:
                                st.warning(f"'{flowNm}' ë°ì´í„°ì— ì´ë¯¸ì§€ URLì´ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                # 3. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                                response_img = requests.get(image_url)
                                image_data = response_img.content

                                # 4. ì´ë¯¸ì§€ ê°ì²´ ë³€í™˜
                                pil_img = Image.open(io.BytesIO(image_data))

                                # 5. Streamlitì— ì¶œë ¥
                                st.image(pil_img, caption=flowNm)
                    st.write(text)



    if user_input := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ì…ë ¥ ì¦‰ì‹œ í‘œì‹œ
        with st.chat_message("user"):
            st.write(user_input)
        
        # Action ê²°ì • ë¡œì§
        action = "None"
        actual_input = user_input

        if user_input.lower() == "ì¢…ë£Œ":
            action = "Exit"
        elif user_input.lower() == "qna":
            action = "QnA"
            actual_input = "ì•ˆë…•? ìê¸°ì†Œê°œ í•´ì¤˜" # ìƒíƒœ ì „í™˜ íŠ¸ë¦¬ê±°ìš©
        elif user_input.lower() == "next" or user_input == "ì¶”ì²œí•´ì¤˜":
            action = "Continue" # í˜¹ì€ ë¡œì§ì— ë”°ë¼ Skip
            actual_input = "ì¶”ì²œí•´ì¤˜"

        input_payload = {
            "messages": [HumanMessage(content=actual_input)],
            "user_action": action
        }

        with st.chat_message("assistant", avatar="ğŸŒ¿"):
            with st.spinner("ìƒê° ì¤‘..."):
                # Graph ì‹¤í–‰
                result = app.invoke(input_payload, config=config)
                
                # ë§ˆì§€ë§‰ ì‘ë‹µ ì¶œë ¥
                last_msg = result["messages"][-1]
                if isinstance(last_msg, AIMessage):
                    response, flowNm = parse_ai_content(last_msg.content)
                    if flowNm is not None:
                        with open("datas/flower_preprocessed_data.json", "r", encoding="utf-8") as f:
                            flower_list = json.load(f)

                        target = next((item for item in flower_list if item.get("flowNm") == flowNm), None)

                        if target is None:
                            st.warning(f"'{flowNm}' ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            image_url = target.get("imgUrl1")

                            if not image_url:
                                st.warning(f"'{flowNm}' ë°ì´í„°ì— ì´ë¯¸ì§€ URLì´ ì—†ìŠµë‹ˆë‹¤.")
                            else:
                                response_img = requests.get(image_url)
                                image_data = response_img.content

                                pil_img = Image.open(io.BytesIO(image_data))

                                st.image(pil_img, caption=flowNm)
                    st.write(response)
                    
